## ONT and PacBio Kinnex single-cell RNA-seq mapping, quantification and alternative splicing data processing pipeine

This pipeline can be used to automate the processing of single-cell RNA-seq data generated by ONT and PacBio Kinnex protocols. It was developed using Snakemake with Conda environments for handling dependencies. Given platform specific requirements for pre-processing of ONT and PacBio data, this pipeline utilises different tools for the steps involved up to mapping of sequencing data based on the specified input platform (i.e., ONT or PacBio). The ONT data pre-processing pipeline is a slightly modified version of single-cell workflow provided by epi2me-labs [wf-single-cell](https://github.com/epi2me-labs/wf-single-cell). The PacBio pre-processing pipeline is very similar to recommended upstream data processing pipeline by PacBio Isoseq pipeline [isoseq.how](https://isoseq.how/umi/). After mapping data from both platforms are treated the same and go through the following processing steps: 

- Transcript models are generated by collapsing redundant reads.
- Transcript models are filtered to remove erroneous models based on SQANTI3 QC
- A hybrid transcriptome is generated
- Mapped reads are filtered based on accepted transcript models
- gene and transcript level count matrix generated
- Filtered reads then can be used in conjuction with downstream cell-type clusters to perform PSI calculations using [Insplico](https://gitlab.com/aghr/insplico).

**Input:**

- PacBio: Demultiplexed PacBio BAM files (unprocessed)
- ONT: Demultiplexed fastq files

**System requirements:**

- Snakemake v7.0 and above

### Usage

If `snakemake` is not installed on your local system, simplest way to install `snakemake` is by creating a new conda environment with an isolated Snakemake installation:

```
mamba create -n snakemake -c conda-forge -c bioconda snakemake;
mamba activate snakemake
```

Then in the activated `snakemake` environment execute the following command from [pipeline_root](#pipeline-directory-structure):

```
snakemake -j 16 --use-conda --rerun-incomplete
```

The pipeline's layout has been designed around Snakemake recommended best practices [Snakemake.readthedocs.io](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html). To that extend, any supplied input file and resource to the pipeline can be provided as described below:

- `config/config.yaml`: All inputs are accessible in the pipeline from this config file. This includes reference sequences, annotations and other supplementary input files. Note that there are different supplementary files required for ONT and PacBio data. Hence, required input files are tagged with Universal, PB or ONT in the example config file below. Universal and platform specific input files must be supplied for successful execution of the pipeline. **Note that a number of config inputs are PacBio or ONT specific and the rest are shared for both pipelines. Input config arguments that are shared between pipelines are mandatory and highlighted as 'Universal'. Pacbio specific inputs are highlighted as 'PB' and ONT specific inputs are highlighted as 'ONT'. For processing PB data only Universal and PB input config files are required; for processing ONT data only Universal and ONT input config files are required.**

**Example config file:**
```
# Sample sheet with predefined columns (note that the sample_id for a given input should be the same for sample.tsv and units.tsv) - Universal
samples: config/samples.tsv
# Input file path (i.e, initial BAM for PacBio input, or Fastq for ONT input) - Universal
units: config/units.tsv
# Whether the PacBio BAM input is already segmented given Kinnex data - Universal
is_segmented: False
# Whether the input file is a PacBio or ONT (i.e., if ONT is_pacbio: False) - Universal
is_pacbio: False
# Library design for PacBio Kinnex data (i,e,. transcript-12bp UMI-16bp cell barcode) - PB
lib_design: T-12U-16B
# 10X library chemistry and version (i.e., 3' or 5', v2, v3, v4) - ONT
sc_kit: 3prime:v2
# Prefix for mitochondial gene names (e.g., for hg38 'MT-') - ONT
mito_prefix: mt-
# Directory path for reference files given ONT data (reference genome should be indexed and organised as fasta/genome.fa and reference annotation should be organised as genes/genes.gtf) - ONT
ont_ref: /data/local/rajewsky/home/mzardba/ref/mm39/wf_sc_ont_ref
# Path to Kinnex/MASSEQ primer sequences for segmentation - PB
mas_primers: /data/local/rajewsky/home/mzardba/ref/primers/mas16_primers.fasta
# Path to file for 10X specific primer sequences - PB
primers: /data/local/rajewsky/home/mzardba/ref/primers/10x_3kit_primers.fasta
# Path to file for 10X specific barcode whitelist file - PB
barcode_whitelist: /data/local/rajewsky/home/mzardba/ref/10x_barcodes/3M-february-2018-REVERSE-COMPLEMENTED.txt.gz
# Minimap2 reference index file - PB
ref_mmi: /data/local/rajewsky/home/mzardba/ref/hg38/GRCh38.primary_assembly.genome.mmi
# Reference sequence file - Universal
ref_fa: /data/rajewsky/home/mzardba/ref/mm39/wf_sc_ont_ref/fasta/genome.fa
# Reference annotation file in BED format - Universal
anno_bed: /data/rajewsky/home/mzardba/ref/mm39/gencode.vM35.primary_assembly.annotation.bed
# Reference annotation in GTF format - Universal
anno_gtf: /data/rajewsky/home/mzardba/ref/mm39/wf_sc_ont_ref/genes/genes.gtf
# Transcript start site file - Universal
tss: /data/rajewsky/home/mzardba/ref/mm39/refTSS_v4.1_mouse_coordinate.mm39.bed
# PolyA motifs sequence file - Universal
polyA_motif: /data/rajewsky/home/mzardba/ref/mm39/polyA.list.txt
# PolyA sites in BED format - Universal
polyA_sites: /data/local/rajewsky/home/mzardba/ref/hg38/polyASites.clusters.2.0.GRCh38.96.gencode.bed
```

#### Pipeline directory structure

User specific inputs should be provided via `config/` files. Input reference files (e.g., species specific annotation and genome fasta files) must be specified by user in `config/config.yaml`. Sample metadata including a `sample_id` must be supplied in `config/samples.tsv`. Sample input files (i.e., genome mapped sorted and indexed BAM) must be supplied in `config/units.tsv`. **Note that `sample_id` is used as primary key and therefore, must be the same value for a given sample in both `config/samples.tsv` and `config/units.tsv` files.**

Pipeline output files are stored in `results/` and each sample output is prefixed with the supplied `sample_id` value.

```
pipeline_root
├── workflow
│   ├── rules 
|   │   ├── commons.smk
|   │   └── qc.smk
│   ├── envs
│   ├── scripts
|   └── Snakefile
├── config
│   ├── config.yaml (modify config and provide required reference input files)
│   └── samples.tsv (add your sample meta data)
|   └── units.tsv (add your sample input file path)
├── results (pipeline output)
└── resources
```