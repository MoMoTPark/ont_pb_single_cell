### Single-cell ONT and PacBio Kinnex mapping, quantification and alternative splicing data processing pipeine

This pipeline can be used to automate the processing of single-cell RNA-seq data generated from ONT direct RNA sequencing and PacBio Kinnex protocols. It was developed using Snakemake with Conda environments for handling dependencies. Given platform specific requirements for pre-processing of ONT and PacBio data, this pipeline is utlises different tools up to the initial mapping of sequencing data based on the specified input platform (i.e., ONT or PacBio). The ONT data pre-processing pipeline is a slightly modified version of single-cell workflow provided by epi2me-labs [wf-single-cell](https://github.com/epi2me-labs/wf-single-cell). The PacBio pre-processing pipeline is very similar to recommended upstream data processing pipeline by PacBio Isoseq pipeline [isoseq.how](https://isoseq.how/umi/). After mapping data from both platforms are treated the same and go through the following processing steps: 

- Transcript models are generated by collapsing redundant reads.
- Transcript models are filtered to remove erroneous models based on SQANTI3 QC
- A hybrid transcriptome is generated then the data is quantified
- Mapped reads are filtered based on accepted transcript models
- Filtered reads then can be used in conjuction with downstream cell-type clusters to perform PSI calculations using [Insplico](https://gitlab.com/aghr/insplico).

#### How to run

The pipeline's layout has been designed around Snakemake recommended best practices [Snakemake.readthedocs.io](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html). To that extend, any supplied input file and resource to the pipeline can be provided as described below (note that all config inputs are mandatory):

- `config/config.yaml`: All inputs are accessible in the pipeline from this config file. This includes reference sequences, annotations and other supplementary input files. Note that there are different supplementary files required for ONT and PacBio data. Hence, input files are tagged with Universal, PB or ONT. Universal and platform specific input files must be supplied for successful execution of the pipeline.

```
# Sample sheet with predefined columns (note that the sample_id for a given input should be the same for sample.tsv and units.tsv) - Universal
samples: config/samples.tsv
# Input file path (i.e, initial BAM for PacBio input, or Fastq for ONT input) - Universal
units: config/units.tsv
# Whether the PacBio BAM input is already segmented given Kinnex data - Universal
is_segmented: False
# Whether the input file is a PacBio or ONT (i.e., if ONT is_pacbio: False) - Universal
is_pacbio: False
# Library design for PacBio Kinnex data (i,e,. transcript-12bp UMI-16bp cell barcode) - PB
lib_design: T-12U-16B
# 10X library chemistry and version (i.e., 3' or 5', v2, v3, v4) - ONT
sc_kit: 3prime:v2
# Prefix for mitochondial gene names (e.g., for hg38 'MT-') - ONT
mito_prefix: mt-
# Directory path for reference files given ONT data (reference genome should be indexed and organised as fasta/genome.fa and reference annotation should be organised as genes/genes.gtf) - ONT
ont_ref: /data/local/rajewsky/home/mzardba/ref/mm39/wf_sc_ont_ref
# Path to Kinnex/MASSEQ primer sequences for segmentation - PB
mas_primers: /data/local/rajewsky/home/mzardba/ref/primers/mas16_primers.fasta
# Path to file for 10X specific primer sequences - PB
primers: /data/local/rajewsky/home/mzardba/ref/primers/10x_3kit_primers.fasta
# Path to file for 10X specific barcode whitelist file - PB
barcode_whitelist: /data/local/rajewsky/home/mzardba/ref/10x_barcodes/3M-february-2018-REVERSE-COMPLEMENTED.txt.gz
# Minimap2 reference index file - PB
ref_mmi: /data/local/rajewsky/home/mzardba/ref/hg38/GRCh38.primary_assembly.genome.mmi
# Reference sequence file - Universal
ref_fa: /data/rajewsky/home/mzardba/ref/mm39/wf_sc_ont_ref/fasta/genome.fa
# Reference annotation file in BED format - Universal
anno_bed: /data/rajewsky/home/mzardba/ref/mm39/gencode.vM35.primary_assembly.annotation.bed
# Reference annotation in GTF format - Universal
anno_gtf: /data/rajewsky/home/mzardba/ref/mm39/wf_sc_ont_ref/genes/genes.gtf
# Transcript start site file - Universal
tss: /data/rajewsky/home/mzardba/ref/mm39/refTSS_v4.1_mouse_coordinate.mm39.bed
# PolyA motifs sequence file - Universal
polyA_motif: /data/rajewsky/home/mzardba/ref/mm39/polyA.list.txt
# PolyA sites in BED format - Universal
polyA_sites: /data/local/rajewsky/home/mzardba/ref/hg38/polyASites.clusters.2.0.GRCh38.96.gencode.bed
```

- `config/samples.tsv`: A sample sheet with predefined columns.
- `config/units.tsv`: Input file paths (`sample_id` must match `samples.tsv`).

The run command depends on the use case of the pipeline. The following command would be the most common way to run this pipeline (add `-n` argument for a dryrun):  
`snakemake -j 64 --rerun-incomplete --use-conda`

**Note:**  
Full path of input files should be supplied in `config/units.tsv` prior to running the test process.  
Sample related information stored at `config/samples.tsv`.  
Input file path provided for each sample at `units.tsv` ('sample_id' column must match between `units.tsv` and `samples.tsv`)